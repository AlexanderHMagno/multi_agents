{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ¨ Agentic Ad Generation with Image Support\n",
    "\n",
    "This notebook implements a sophisticated multi-agent system for generating advertising content with integrated image generation capabilities. The system uses LangChain and LangGraph to coordinate multiple specialized agents that work together to create compelling ad campaigns.\n",
    "\n",
    "## ðŸ”‘ Setup & Configuration\n",
    "\n",
    "First, we'll install the required packages and set up our environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install python-dotenv langchain langgraph openai langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n",
      "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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access environment variables\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "DALLE_API_KEY = os.getenv(\"DALLE_API_KEY\")\n",
    "\n",
    "# print(OPENAI_API_KEY)\n",
    "# print(DALLE_API_KEY)\n",
    "# Verify API keys are loaded\n",
    "if not OPENAI_API_KEY or not DALLE_API_KEY:\n",
    "    raise ValueError(\"Please ensure both OPENAI_API_KEY and DALLE_API_KEY are set in your .env file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Import Required Libraries\n",
    "\n",
    "We'll import all the necessary libraries for our multi-agent system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List, TypedDict\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.checkpoint.memory import MemorySaver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ¤– Define State and Base Classes\n",
    "\n",
    "First, we'll define our state management and base agent classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define state structure\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    campaign_brief: dict\n",
    "    artifacts: dict\n",
    "    feedback: list\n",
    "    revision_count: int\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    model_name=\"openai/gpt-4o-mini\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# Base Agent class\n",
    "class BaseAgent:\n",
    "    def __init__(self, system_prompt: str):\n",
    "        self.system_prompt = system_prompt\n",
    "        self.llm = llm\n",
    "    \n",
    "    def get_messages(self, content: str) -> List:\n",
    "        return [\n",
    "            SystemMessage(content=self.system_prompt),\n",
    "            HumanMessage(content=content)\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ‘¥ Implement Agent Teams\n",
    "\n",
    "Now we'll implement each specialized agent team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project Manager Agent\n",
    "class ProjectManager(BaseAgent):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            system_prompt=\"\"\"You are a project manager coordinating an ad campaign creation.\n",
    "            Your role is to oversee the entire workflow and ensure all teams are aligned.\n",
    "            Analyze the current state and decide on next actions.\"\"\"\n",
    "        )\n",
    "    \n",
    "    def run(self, state: State) -> dict:\n",
    "        messages = self.get_messages(f\"Current state: {state}. What should be our next action?\")\n",
    "        response = self.llm.invoke(messages)\n",
    "        return {\"messages\": [response]}\n",
    "\n",
    "# Strategy Team\n",
    "class StrategyTeam(BaseAgent):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            system_prompt=\"\"\"You are the strategy team responsible for analyzing campaign requirements.\n",
    "            Provide strategic recommendations for targeting, messaging, and positioning.\n",
    "            Focus on actionable insights that will guide creative development.\"\"\"\n",
    "        )\n",
    "    \n",
    "    def run(self, state: State) -> dict:\n",
    "        messages = self.get_messages(f\"Analyze this campaign brief: {state['campaign_brief']}\")\n",
    "        response = self.llm.invoke(messages)\n",
    "        return {\"messages\": [response], \"artifacts\": {\"strategy\": response.content}}\n",
    "\n",
    "# Creative Team\n",
    "class CreativeTeam(BaseAgent):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            system_prompt=\"\"\"You are the creative team responsible for generating innovative ad concepts.\n",
    "            Generate compelling creative concepts that align with the strategy.\n",
    "            Include visual direction and thematic elements.\"\"\"\n",
    "        )\n",
    "    \n",
    "    def run(self, state: State) -> dict:\n",
    "        strategy = state['artifacts'].get('strategy', '')\n",
    "        messages = self.get_messages(f\"Based on this strategy: {strategy}, generate creative concepts.\")\n",
    "        response = self.llm.invoke(messages)\n",
    "        return {\"messages\": [response], \"artifacts\": {\"creative_concepts\": response.content}}\n",
    "\n",
    "# Copy Team\n",
    "class CopyTeam(BaseAgent):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            system_prompt=\"\"\"You are the copywriting team responsible for creating compelling ad copy.\n",
    "            Write engaging headlines, body copy, and calls-to-action that align with the creative concepts.\n",
    "            Ensure copy is persuasive and on-brand.\"\"\"\n",
    "        )\n",
    "    \n",
    "    def run(self, state: State) -> dict:\n",
    "        concepts = state['artifacts'].get('creative_concepts', '')\n",
    "        messages = self.get_messages(f\"Based on these concepts: {concepts}, write the ad copy.\")\n",
    "        response = self.llm.invoke(messages)\n",
    "        return {\"messages\": [response], \"artifacts\": {\"copy\": response.content}}\n",
    "\n",
    "# Visual Team\n",
    "class VisualTeam(BaseAgent):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            system_prompt=\"\"\"You are the visual team responsible for creating ad imagery.\n",
    "            Generate detailed image prompts that align with the creative concept and copy.\n",
    "            Focus on creating visually striking and memorable imagery.\"\"\"\n",
    "        )\n",
    "        self.image_llm = ChatOpenAI(\n",
    "            openai_api_key=DALLE_API_KEY,\n",
    "            model_name=\"gpt-4.1-mini\"\n",
    "        )\n",
    "    \n",
    "    def run(self, state: State) -> dict:\n",
    "        copy = state['artifacts'].get('copy', '')\n",
    "        concepts = state['artifacts'].get('creative_concepts', '')\n",
    "        \n",
    "        # Generate image prompt\n",
    "        messages = self.get_messages(\n",
    "            f\"Based on this copy: {copy} and concepts: {concepts}, create a detailed image prompt.\"\n",
    "        )\n",
    "        prompt_response = self.image_llm.invoke(messages)\n",
    "        \n",
    "        # Here you would call DALL-E API with the generated prompt\n",
    "        # For now, we'll just store the prompt\n",
    "        return {\"messages\": [prompt_response], \"artifacts\": {\"image_prompt\": prompt_response.content}}\n",
    "\n",
    "# Review Team\n",
    "class ReviewTeam(BaseAgent):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            system_prompt=\"\"\"You are the review team responsible for evaluating the campaign.\n",
    "            Assess the strategy, creative, copy, and visuals for effectiveness and alignment.\n",
    "            Provide specific feedback and recommendations for improvements.\"\"\"\n",
    "        )\n",
    "    \n",
    "    def run(self, state: State) -> dict:\n",
    "        artifacts = state['artifacts']\n",
    "        messages = self.get_messages(f\"Review these campaign elements: {artifacts}\")\n",
    "        response = self.llm.invoke(messages)\n",
    "        return {\"messages\": [response], \"feedback\": [response.content]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”„ Create Workflow Graph\n",
    "\n",
    "Now we'll connect all our agent teams into a coordinated workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_workflow():\n",
    "    # Initialize teams\n",
    "    pm = ProjectManager()\n",
    "    strategy = StrategyTeam()\n",
    "    creative = CreativeTeam()\n",
    "    copy = CopyTeam()\n",
    "    visual = VisualTeam()\n",
    "    review = ReviewTeam()\n",
    "    \n",
    "    # Create graph\n",
    "    workflow = StateGraph(State)\n",
    "    \n",
    "    # Add nodes\n",
    "    workflow.add_edge(START, \"project_manager\")\n",
    "    workflow.add_node(\"project_manager\", pm.run)\n",
    "    workflow.add_node(\"strategy\", strategy.run)\n",
    "    workflow.add_node(\"creative\", creative.run)\n",
    "    workflow.add_node(\"copy\", copy.run)\n",
    "    workflow.add_node(\"visual\", visual.run)\n",
    "    workflow.add_node(\"review\", review.run)\n",
    "    \n",
    "    # Define edges\n",
    "    workflow.add_edge(\"project_manager\", \"strategy\")\n",
    "    workflow.add_edge(\"strategy\", \"creative\")\n",
    "    workflow.add_edge(\"creative\", \"copy\")\n",
    "    workflow.add_edge(\"copy\", \"visual\")\n",
    "    workflow.add_edge(\"visual\", \"review\")\n",
    "    workflow.add_edge(\"review\", \"project_manager\")\n",
    "    \n",
    "    # Add conditional edges for feedback loops\n",
    "    def needs_revision(state):\n",
    "        feedback = state.get(\"feedback\", [])\n",
    "        revision_count = state.get(\"revision_count\", 0)\n",
    "\n",
    "        if revision_count >= 3:\n",
    "            print(\"âš ï¸ Max revisions reached. Completing workflow.\")\n",
    "            return \"complete\"\n",
    "\n",
    "        if feedback:\n",
    "            last = feedback[-1].lower()\n",
    "            state[\"revision_count\"] += 1\n",
    "            if \"copy\" in last:\n",
    "                return \"copy\"\n",
    "            elif \"visual\" in last:\n",
    "                return \"visual\"\n",
    "            elif \"strategy\" in last or \"revise\" in last:\n",
    "                return \"strategy\"\n",
    "\n",
    "        return \"complete\"\n",
    "    \n",
    "    workflow.add_conditional_edges(\n",
    "        \"project_manager\",\n",
    "        needs_revision,\n",
    "        {\n",
    "            \"revise\": \"strategy\",\n",
    "            \"complete\": END\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return workflow\n",
    "\n",
    "# Create workflow with memory\n",
    "memory = MemorySaver()\n",
    "workflow = create_workflow()\n",
    "workflow_with_memory = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Analytics Implementation\n",
    "\n",
    "Let's implement our analytics tracking system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CampaignAnalytics:\n",
    "    def __init__(self):\n",
    "        self.metrics = {\n",
    "            \"iterations\": 0,\n",
    "            \"team_performance\": {},\n",
    "            \"quality_scores\": {},\n",
    "            \"timing\": {}\n",
    "        }\n",
    "    \n",
    "    def track_iteration(self, state: dict):\n",
    "        self.metrics[\"iterations\"] += 1\n",
    "        # Add performance tracking for each team\n",
    "        for team, artifact in state.get('artifacts', {}).items():\n",
    "            if team not in self.metrics[\"team_performance\"]:\n",
    "                self.metrics[\"team_performance\"][team] = []\n",
    "            self.metrics[\"team_performance\"][team].append(len(artifact))\n",
    "    \n",
    "    def generate_report(self) -> dict:\n",
    "        return {\n",
    "            \"summary\": self._generate_summary(),\n",
    "            \"recommendations\": self._generate_recommendations(),\n",
    "            \"performance\": self.metrics\n",
    "        }\n",
    "    \n",
    "    def _generate_summary(self):\n",
    "        return f\"Campaign generated in {self.metrics['iterations']} iterations\"\n",
    "    \n",
    "    def _generate_recommendations(self):\n",
    "        recommendations = []\n",
    "        \n",
    "        # Analyze team performance\n",
    "        for team, performances in self.metrics[\"team_performance\"].items():\n",
    "            avg_performance = sum(performances) / len(performances)\n",
    "            if avg_performance < 100:  # Example threshold\n",
    "                recommendations.append(f\"Consider providing more detailed input to {team}\")\n",
    "        \n",
    "        return recommendations\n",
    "\n",
    "# Initialize analytics\n",
    "analytics = CampaignAnalytics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš€ Run Campaign Generation\n",
    "\n",
    "Let's test our system with a sample campaign brief."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "GraphRecursionError",
     "evalue": "Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mGraphRecursionError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Run workflow\u001b[39;00m\n\u001b[32m     24\u001b[39m config = {\u001b[33m\"\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mthread_id\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33meco-bottle-campaign\u001b[39m\u001b[33m\"\u001b[39m}}\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m result = \u001b[43mworkflow_with_memory\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Track analytics\u001b[39;00m\n\u001b[32m     28\u001b[39m analytics.track_iteration(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langgraph/pregel/__init__.py:2844\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, **kwargs)\u001b[39m\n\u001b[32m   2841\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   2842\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2844\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2845\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2846\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2847\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   2848\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   2849\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2850\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2851\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2852\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2853\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2854\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2855\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2856\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2857\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langgraph/pregel/__init__.py:2559\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2550\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m loop.status == \u001b[33m\"\u001b[39m\u001b[33mout_of_steps\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2551\u001b[39m     msg = create_error_message(\n\u001b[32m   2552\u001b[39m         message=(\n\u001b[32m   2553\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRecursion limit of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[33m'\u001b[39m\u001b[33mrecursion_limit\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m reached \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2557\u001b[39m         error_code=ErrorCode.GRAPH_RECURSION_LIMIT,\n\u001b[32m   2558\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2559\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m GraphRecursionError(msg)\n\u001b[32m   2560\u001b[39m \u001b[38;5;66;03m# set final channel values as run output\u001b[39;00m\n\u001b[32m   2561\u001b[39m run_manager.on_chain_end(loop.output)\n",
      "\u001b[31mGraphRecursionError\u001b[39m: Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT"
     ]
    }
   ],
   "source": [
    "# Sample campaign brief\n",
    "campaign_brief = {\n",
    "    \"product\": \"Eco-friendly Water Bottle\",\n",
    "    \"target_audience\": \"Environmentally conscious millennials\",\n",
    "    \"goals\": [\"Increase brand awareness\", \"Drive online sales\"],\n",
    "    \"key_features\": [\n",
    "        \"Made from recycled materials\",\n",
    "        \"Keeps drinks cold for 24 hours\",\n",
    "        \"Portion of profits goes to ocean cleanup\"\n",
    "    ],\n",
    "    \"budget\": \"$50,000\",\n",
    "    \"timeline\": \"4 weeks\"\n",
    "}\n",
    "\n",
    "# Initialize state\n",
    "initial_state = {\n",
    "    \"messages\": [],\n",
    "    \"campaign_brief\": campaign_brief,\n",
    "    \"artifacts\": {},\n",
    "    \"feedback\": [],\n",
    "    \"revision_count\": 0\n",
    "}\n",
    "\n",
    "# Run workflow\n",
    "config = {\"configurable\": {\"thread_id\": \"eco-bottle-campaign\"}}\n",
    "result = workflow_with_memory.invoke(initial_state, config)\n",
    "\n",
    "# Track analytics\n",
    "analytics.track_iteration(result)\n",
    "\n",
    "# Display results\n",
    "print(\"Campaign Results:\\n\")\n",
    "print(\"Strategy:\")\n",
    "print(result['artifacts'].get('strategy', ''))\n",
    "print(\"\\nCreative Concepts:\")\n",
    "print(result['artifacts'].get('creative_concepts', ''))\n",
    "print(\"\\nCopy:\")\n",
    "print(result['artifacts'].get('copy', ''))\n",
    "print(\"\\nImage Prompt:\")\n",
    "print(result['artifacts'].get('image_prompt', ''))\n",
    "print(\"\\nFeedback:\")\n",
    "print(result.get('feedback', []))\n",
    "\n",
    "# Display analytics\n",
    "print(\"\\nAnalytics Report:\")\n",
    "report = analytics.generate_report()\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
